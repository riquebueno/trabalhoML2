{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection Demo\n",
    "Welcome to the object detection inference walkthrough!  This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image. Make sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md) before you start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henriquebueno/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if tf.__version__ < '1.4.0':\n",
    "  raise ImportError('Please upgrade your tensorflow installation to v1.4.* or later!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/models-master/research/object_detection/utils/visualization_utils.py:25: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-5a31747f16e3>\", line 2, in <module>\n",
      "    get_ipython().magic('matplotlib inline')\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2158, in magic\n",
      "    return self.run_line_magic(magic_name, magic_arg_s)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2079, in run_line_magic\n",
      "    result = fn(*args,**kwargs)\n",
      "  File \"<decorator-gen-104>\", line 2, in matplotlib\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/magic.py\", line 188, in <lambda>\n",
      "    call = lambda f, *a, **k: f(*a, **k)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/magics/pylab.py\", line 100, in matplotlib\n",
      "    gui, backend = self.shell.enable_matplotlib(args.gui)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2949, in enable_matplotlib\n",
      "    pt.activate_matplotlib(backend)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 308, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/Users/henriquebueno/anaconda/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_CKPT` to point to a new .pb file.  \n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "#print(categories)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the sake of simplicity we will use only 2 images:\n",
    "# image1.jpg\n",
    "# image2.jpg\n",
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "#PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
    "PATH_TO_TEST_IMAGES_DIR = '/Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data'\n",
    "#TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]\n",
    "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}.jpg'.format(i)) for i in [0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,20,22,23,24,25,26,27,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,57,58,59,60,61,62,63,64,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134] ]\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "#IMAGE_SIZE = (12, 8)\n",
    "IMAGE_SIZE = (490, 326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(image, graph):\n",
    "  with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "      ops = tf.get_default_graph().get_operations()\n",
    "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "      tensor_dict = {}\n",
    "      for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "      if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "      # Run inference\n",
    "      output_dict = sess.run(tensor_dict,\n",
    "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "      output_dict['detection_classes'] = output_dict[\n",
    "          'detection_classes'][0].astype(np.uint8)\n",
    "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "      if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "  return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "#aaa\n",
    "def temTelefone(detection_boxes1, detection_classes1, detection_scores1, fileName):\n",
    "\n",
    "    xEstimado = -1\n",
    "    yEstimado = -1\n",
    "    for pos in range(len(detection_classes1)):\n",
    "        if detection_classes1[pos]==77:#classe cell phone\n",
    "            #print(\"Nome do arquivo: \" + str(filename))\n",
    "            coordenadas = detection_boxes1[pos]\n",
    "            #print(\"Posicao do celular encontrado: \" + str(coordenadas))\n",
    "            ymin = coordenadas[0]\n",
    "            xmin = coordenadas[1]\n",
    "            ymax = coordenadas[2]\n",
    "            xmax = coordenadas[3]\n",
    "            #print(\"Y min: \" + str(ymin))\n",
    "            #print(\"X min: \" + str(xmin))\n",
    "            #print(\"Y max: \" + str(ymax))\n",
    "            #print(\"X max: \" + str(xmax))\n",
    "            xEstimado=(xmin+xmax)/2\n",
    "            yEstimado=(ymin+ymax)/2\n",
    "            #xCorreto0=0.8306 \n",
    "            #yCorreto0=0.1350\n",
    "\n",
    "            #TAMBÉM PRECISA ALTERAR A CELULA DETECTION--------------------------\n",
    "\n",
    "            #Nao achou para a 1.jpg\n",
    "            #xCorreto1=0.8714\n",
    "            #yCorreto1=0.1718\n",
    "\n",
    "            #xCorreto3=0.6857\n",
    "            #yCorreto3=0.6933\n",
    "\n",
    "            #print(\"Ponto: \" + str(xEstimado) + \" - \" + str(yEstimado))\n",
    "            #print(\"Score do celular encontrado: \" + str(detection_scores1[pos]))\n",
    "            #dist = math.hypot(xEstimado - xCorreto3, yEstimado - yCorreto3)\n",
    "            #print(\"Distancia: \" + str(dist))\n",
    "            \n",
    "    return xEstimado, yEstimado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/0.jpg x, y= 0.8279541730880737-0.14251825213432312\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/1.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/3.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/4.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/5.jpg x, y= 0.8460574150085449-0.2203872948884964\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/6.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/7.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/8.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/9.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/10.jpg x, y= 0.4893141984939575-0.4276229739189148\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/11.jpg x, y= 0.8135676383972168-0.6884363889694214\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/12.jpg x, y= 0.18572084605693817-0.8693500757217407\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/13.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/14.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/15.jpg x, y= 0.2805520296096802-0.887049674987793\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/16.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/17.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/18.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/20.jpg x, y= 0.349510133266449-0.7803120017051697\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/22.jpg x, y= 0.19889631867408752-0.5786418914794922\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/23.jpg x, y= 0.41529399156570435-0.6215883493423462\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/24.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/25.jpg x, y= 0.5623406171798706-0.25560569763183594\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/26.jpg x, y= 0.25448527932167053-0.7512201070785522\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/27.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/29.jpg x, y= 0.20411613583564758-0.36573705077171326\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/30.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/31.jpg x, y= 0.6459662318229675-0.36515599489212036\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/32.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/33.jpg x, y= 0.11770085990428925-0.3598319888114929\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/34.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/35.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/36.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/37.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/38.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/39.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/40.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/41.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/42.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/43.jpg x, y= 0.6701391339302063-0.38526540994644165\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/44.jpg x, y= 0.12277188152074814-0.5536558032035828\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/45.jpg x, y= 0.8838511109352112-0.44174131751060486\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/46.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/47.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/48.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/49.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/50.jpg x, y= 0.4128592312335968-0.7852169275283813\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/51.jpg x, y= 0.244165301322937-0.6083588600158691\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/52.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/53.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/54.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/55.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/57.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/58.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/59.jpg x, y= 0.3416704833507538-0.7238467931747437\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/60.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/61.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/62.jpg x, y= 0.14843793213367462-0.2578059732913971\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/63.jpg x, y= 0.29646286368370056-0.8360402584075928\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/64.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/66.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/67.jpg x, y= 0.07228108495473862-0.823952853679657\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/68.jpg x, y= 0.09792774170637131-0.140174999833107\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/69.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/70.jpg x, y= 0.42451047897338867-0.2449510097503662\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/71.jpg x, y= 0.8355889916419983-0.7492465972900391\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/72.jpg x, y= 0.6892507076263428-0.37894192337989807\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/73.jpg x, y= 0.4734117090702057-0.5429844260215759\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/74.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/75.jpg x, y= 0.7820836305618286-0.7506694793701172\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/76.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/77.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/78.jpg x, y= 0.7476404905319214-0.4878605604171753\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/79.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/80.jpg x, y= 0.7735908627510071-0.27942484617233276\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/81.jpg x, y= 0.4994810223579407-0.8610057234764099\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/82.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/83.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/84.jpg x, y= 0.7138906121253967-0.7171392440795898\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/85.jpg x, y= 0.18556693196296692-0.252791166305542\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/86.jpg x, y= 0.2360023856163025-0.21712663769721985\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/87.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/88.jpg x, y= 0.3245512843132019-0.3311378061771393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/89.jpg x, y= 0.27636921405792236-0.36228370666503906\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/90.jpg x, y= 0.26956188678741455-0.516847550868988\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/91.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/92.jpg x, y= 0.6398442387580872-0.711186408996582\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/93.jpg x, y= 0.7864146828651428-0.27324995398521423\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/94.jpg x, y= 0.3434356451034546-0.46020495891571045\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/95.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/96.jpg x, y= 0.47976329922676086-0.855712890625\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/97.jpg x, y= 0.7575002908706665-0.4359394311904907\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/98.jpg x, y= 0.5502379536628723-0.8164337277412415\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/99.jpg x, y= 0.37897253036499023-0.5366571545600891\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/100.jpg x, y= 0.8165485858917236-0.8515129089355469\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/101.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/102.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/103.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/104.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/105.jpg x, y= 0.5684890747070312-0.8643856644630432\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/106.jpg x, y= 0.6711861491203308-0.3822445869445801\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/107.jpg x, y= 0.22638866305351257-0.4780203104019165\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/108.jpg x, y= 0.48543766140937805-0.4911506175994873\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/109.jpg x, y= 0.8132228851318359-0.256460577249527\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/110.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/111.jpg x, y= 0.45742666721343994-0.7253848910331726\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/112.jpg x, y= 0.4358154237270355-0.8360869884490967\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/113.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/114.jpg x, y= 0.8002442717552185-0.6756212115287781\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/115.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/116.jpg x, y= 0.4578970670700073-0.7864233255386353\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/117.jpg x, y= 0.6403777003288269-0.22050803899765015\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/118.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/119.jpg x, y= 0.480324923992157-0.45174092054367065\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/120.jpg x, y= 0.8367043137550354-0.7197265625\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/121.jpg x, y= 0.2366151511669159-0.8481993675231934\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/122.jpg x, y= 0.22567331790924072-0.8120811581611633\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/123.jpg x, y= 0.4690103828907013-0.5317183136940002\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/124.jpg\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/125.jpg x, y= 0.892069935798645-0.8298807740211487\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/126.jpg x, y= 0.4492065906524658-0.23704291880130768\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/127.jpg x, y= 0.18933090567588806-0.9058091044425964\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/128.jpg x, y= 0.7182274460792542-0.29349660873413086\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/129.jpg x, y= 0.19227415323257446-0.26917681097984314\n",
      "Sim: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/130.jpg x, y= 0.15584884583950043-0.6466905474662781\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/131.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/132.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/133.jpg\n",
      "Não: /Users/henriquebueno/DOUTORADO/2018.01/ml/trabalho2/find_phone_data/134.jpg\n",
      "% sim: 0.5193798449612403\n",
      "% nao: 0.4806201550387597\n"
     ]
    }
   ],
   "source": [
    "#predicao\n",
    "\n",
    "sim = 0\n",
    "nao = 0\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "  image = Image.open(image_path)\n",
    "  #print(\"abriu \" + str(image.filename))\n",
    "  # the array based representation of the image will be used later in order to prepare the\n",
    "  # result image with boxes and labels on it.\n",
    "  image_np = load_image_into_numpy_array(image)\n",
    "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "  # Actual detection.\n",
    "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "  #print(\"ja rodou inferencia \" + str(image.filename))\n",
    "  # Visualization of the results of a detection.\n",
    "  #vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "  #    image_np,\n",
    "  #    output_dict['detection_boxes'],\n",
    "  #    output_dict['detection_classes'],\n",
    "  #    output_dict['detection_scores'],\n",
    "  #    category_index,\n",
    "  #    instance_masks=output_dict.get('detection_masks'),\n",
    "  #    use_normalized_coordinates=True,\n",
    "  #    line_thickness=8)\n",
    "  #print(\"vis_util.visualize_boxes_and_labels_on_image_array \" + str(image.filename))\n",
    "  #plt.figure(figsize=IMAGE_SIZE)\n",
    "  #print(\"plt.figure \" + str(image.filename))\n",
    "  #plt.imshow(image_np)\n",
    "  #print(\"plt.imshow \" + str(image.filename))\n",
    "\n",
    "  detection_boxes1 = output_dict['detection_boxes']\n",
    "  detection_classes1 = output_dict['detection_classes']\n",
    "  detection_scores1 = output_dict['detection_scores']\n",
    "    \n",
    "  xEstimado, yEstimado = temTelefone(detection_boxes1, detection_classes1, detection_scores1, image.filename)\n",
    "\n",
    "  if((xEstimado==-1)and(yEstimado==-1)):\n",
    "    print(\"Não: \" + str(image.filename))\n",
    "    nao+=1\n",
    "  else:\n",
    "    print(\"Sim: \" + str(image.filename) + \" x, y= \" + str(xEstimado) + \"-\" + str(yEstimado))\n",
    "    sim+=1\n",
    "    \n",
    "#ainda preciso calcular a distancia do celular encontrado para a coordenada do arquivo do professor\n",
    "    \n",
    "print(\"% sim: \" + str(sim/(sim+nao)))\n",
    "print(\"% nao: \" + str(nao/(sim+nao)))\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acabou\n"
     ]
    }
   ],
   "source": [
    "print(\"acabou\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
